{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SHARE MLSpring2021 - HW2-1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChangShengHsun/ML2021-HW/blob/main/HW02/HW02-1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYlaRwNu7ojq"
      },
      "source": [
        "# **Homework 2-1 Phoneme Classification**\n",
        "\n",
        "* Slides: https://speech.ee.ntu.edu.tw/~hylee/ml/ml2021-course-data/hw/HW02/HW02.pdf\n",
        "* Video (Chinese): https://youtu.be/PdjXnQbu2zo\n",
        "* Video (English): https://youtu.be/ESRr-VCykBs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emUd7uS7crTz"
      },
      "source": [
        "## The DARPA TIMIT Acoustic-Phonetic Continuous Speech Corpus (TIMIT)\n",
        "The TIMIT corpus of reading speech has been designed to provide speech data for the acquisition of acoustic-phonetic knowledge and for the development and evaluation of automatic speech recognition systems.\n",
        "\n",
        "This homework is a multiclass classification task,\n",
        "we are going to train a deep neural network classifier to predict the phonemes for each frame from the speech corpus TIMIT.\n",
        "\n",
        "link: https://academictorrents.com/details/34e2b78745138186976cbc27939b1b34d18bd5b3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVUGfWTo7_Oj"
      },
      "source": [
        "## Download Data\n",
        "Download data from google drive, then unzip it.\n",
        "\n",
        "You should have `timit_11/train_11.npy`, `timit_11/train_label_11.npy`, and `timit_11/test_11.npy` after running this block.<br><br>\n",
        "`timit_11/`\n",
        "- `train_11.npy`: training data<br>\n",
        "- `train_label_11.npy`: training label<br>\n",
        "- `test_11.npy`:  testing data<br><br>\n",
        "\n",
        "**notes: if the google drive link is dead, you can download the data directly from Kaggle and upload it to the workspace**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzkiMEcC3Foq",
        "outputId": "bba88121-dca1-4e59-cc92-fb1597b8d1b1"
      },
      "source": [
        "!gdown --id '1HPkcmQmFGu-3OknddKIa5dNDsR05lIQR' --output data.zip\n",
        "!unzip data.zip\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1HPkcmQmFGu-3OknddKIa5dNDsR05lIQR\n",
            "From (redirected): https://drive.google.com/uc?id=1HPkcmQmFGu-3OknddKIa5dNDsR05lIQR&confirm=t&uuid=0d8bf039-9278-41ff-947a-f31188a5434f\n",
            "To: /content/data.zip\n",
            "100% 372M/372M [00:02<00:00, 146MB/s]\n",
            "Archive:  data.zip\n",
            "   creating: timit_11/\n",
            "  inflating: timit_11/train_11.npy   \n",
            "  inflating: timit_11/test_11.npy    \n",
            "  inflating: timit_11/train_label_11.npy  \n",
            "data.zip  sample_data  timit_11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L_4anls8Drv"
      },
      "source": [
        "## Preparing Data\n",
        "Load the training and testing data from the `.npy` file (NumPy array)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJjLT8em-y9G",
        "outputId": "46f9a4ab-b565-4296-be2f-6db4bdaec5e7"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "print('Loading data ...')\n",
        "\n",
        "data_root='./timit_11/'\n",
        "train = np.load(data_root + 'train_11.npy')\n",
        "train_label = np.load(data_root + 'train_label_11.npy')\n",
        "test = np.load(data_root + 'test_11.npy')\n",
        "\n",
        "print('Size of training data: {}'.format(train.shape))\n",
        "print('Size of testing data: {}'.format(test.shape))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data ...\n",
            "Size of training data: (1229932, 429)\n",
            "Size of testing data: (451552, 429)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us5XW_x6udZQ"
      },
      "source": [
        "## Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fjf5EcmJtf4e"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TIMITDataset(Dataset):\n",
        "    def __init__(self, X, y=None):\n",
        "        self.data = torch.from_numpy(X).float()\n",
        "        if y is not None:\n",
        "            y = y.astype(int)\n",
        "            self.label = torch.LongTensor(y)\n",
        "        else:\n",
        "            self.label = None\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.label is not None:\n",
        "            return self.data[idx], self.label[idx]\n",
        "        else:\n",
        "            return self.data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otIC6WhGeh9v"
      },
      "source": [
        "Split the labeled data into a training set and a validation set, you can modify the variable `VAL_RATIO` to change the ratio of validation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYqi_lAuvC59",
        "outputId": "30bcd191-704f-4aa7-cd8f-3a4e8aff00c0"
      },
      "source": [
        "VAL_RATIO = 0.05\n",
        "\n",
        "percent = int(train.shape[0] * (1 - VAL_RATIO))\n",
        "train_x, train_y, val_x, val_y = train[:percent], train_label[:percent], train[percent:], train_label[percent:]\n",
        "print('Size of training set: {}'.format(train_x.shape))\n",
        "print('Size of validation set: {}'.format(val_x.shape))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of training set: (1168435, 429)\n",
            "Size of validation set: (61497, 429)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbCfclUIgMTX"
      },
      "source": [
        "Create a data loader from the dataset, feel free to tweak the variable `BATCH_SIZE` here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUCbQvqJurYc"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_set = TIMITDataset(train_x, train_y)\n",
        "val_set = TIMITDataset(val_x, val_y)\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True) #only shuffle the training data\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SY7X0lUgb50"
      },
      "source": [
        "Cleanup the unneeded variables to save memory.<br>\n",
        "\n",
        "**notes: if you need to use these variables later, then you may remove this block or clean up unneeded variables later<br>the data size is quite huge, so be aware of memory usage in colab**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8rzkGraeYeN",
        "outputId": "5738dbf7-0652-40fe-8baa-b0684f0f4932"
      },
      "source": [
        "import gc\n",
        "\n",
        "del train, train_label, train_x, train_y, val_x, val_y\n",
        "gc.collect()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "609"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRqKNvNZwe3V"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYr1ng5fh9pA"
      },
      "source": [
        "Define model architecture, you are encouraged to change and experiment with the model architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbZrwT6Ny0XL"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.layer1 = nn.Linear(429, 2048)\n",
        "        self.layer2 = nn.Linear(2048, 1024)\n",
        "        self.layer3 = nn.Linear(1024, 512)\n",
        "        self.layer4 = nn.Linear(512, 256)\n",
        "        self.out = nn.Linear(256, 39)\n",
        "\n",
        "        self.act_fn = nn.ReLU()\n",
        "\n",
        "        self.norm1 = nn.BatchNorm1d(2048)\n",
        "        self.norm2 = nn.BatchNorm1d(1024)\n",
        "        self.norm3 = nn.BatchNorm1d(512)\n",
        "        self.norm4 = nn.BatchNorm1d(256)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.norm1(x)\n",
        "        x = self.act_fn(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.layer2(x)\n",
        "        x = self.norm2(x)\n",
        "        x = self.act_fn(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.layer3(x)\n",
        "        x = self.norm3(x)\n",
        "        x = self.act_fn(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.layer4(x)\n",
        "        x = self.norm4(x)\n",
        "        x = self.act_fn(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.out(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRYciXZvPbYh"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y114Vmm3Ja6o"
      },
      "source": [
        "#check device\n",
        "def get_device():\n",
        "  return 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEX-yjHjhGuH"
      },
      "source": [
        "Fix random seeds for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88xPiUnm0tAd"
      },
      "source": [
        "# fix random seed\n",
        "def same_seeds(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbBcBXkSp6RA"
      },
      "source": [
        "Feel free to change the training parameters here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTp3ZXg1yO9Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ace2801e-75d9-4df6-88b8-9a4b0e5b6112"
      },
      "source": [
        "# fix random seed for reproducibility\n",
        "same_seeds(0)\n",
        "\n",
        "# get device\n",
        "device = get_device()\n",
        "print(f'DEVICE: {device}')\n",
        "\n",
        "# training parameters\n",
        "num_epoch = 40               # number of training epoch\n",
        "learning_rate = 0.00005       # learning rate\n",
        "\n",
        "# the path where checkpoint saved\n",
        "model_path = './model.ckpt'\n",
        "\n",
        "# create model, define a loss function, and optimizer\n",
        "model = Classifier().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay= 5e-3)\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICE: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdMWsBs7zzNs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d5a3076-a19d-4f0f-8ede-6720ee61eb7a"
      },
      "source": [
        "# start training\n",
        "\n",
        "best_acc = 0.0\n",
        "for epoch in range(num_epoch):\n",
        "    train_acc = 0.0\n",
        "    train_loss = 0.0\n",
        "    val_acc = 0.0\n",
        "    val_loss = 0.0\n",
        "\n",
        "    # training\n",
        "    model.train() # set the model to training mode\n",
        "    for i, data in enumerate(train_loader):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        batch_loss = criterion(outputs, labels)\n",
        "        _, train_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_acc += (train_pred.cpu() == labels.cpu()).sum().item()\n",
        "        train_loss += batch_loss.item()\n",
        "\n",
        "    # validation\n",
        "    if len(val_set) > 0:\n",
        "        model.eval() # set the model to evaluation mode\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(val_loader):\n",
        "                inputs, labels = data\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                batch_loss = criterion(outputs, labels)\n",
        "                _, val_pred = torch.max(outputs, 1)\n",
        "\n",
        "                val_acc += (val_pred.cpu() == labels.cpu()).sum().item() # get the index of the class with the highest probability\n",
        "                val_loss += batch_loss.item()\n",
        "\n",
        "            print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f} | Val Acc: {:3.6f} loss: {:3.6f}'.format(\n",
        "                epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader), val_acc/len(val_set), val_loss/len(val_loader)\n",
        "            ))\n",
        "\n",
        "            # if the model improves, save a checkpoint at this epoch\n",
        "            if val_acc > best_acc:\n",
        "                best_acc = val_acc\n",
        "                torch.save(model.state_dict(), model_path)\n",
        "                print('saving model with acc {:.3f}'.format(best_acc/len(val_set)))\n",
        "    else:\n",
        "        print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f}'.format(\n",
        "            epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader)\n",
        "        ))\n",
        "\n",
        "# if not validating, save the last epoch\n",
        "if len(val_set) == 0:\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print('saving model at last epoch')\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[001/040] Train Acc: 0.575913 Loss: 1.435381 | Val Acc: 0.677870 loss: 1.026439\n",
            "saving model with acc 0.678\n",
            "[002/040] Train Acc: 0.648512 Loss: 1.125115 | Val Acc: 0.701465 loss: 0.939886\n",
            "saving model with acc 0.701\n",
            "[003/040] Train Acc: 0.670184 Loss: 1.043748 | Val Acc: 0.713758 loss: 0.892128\n",
            "saving model with acc 0.714\n",
            "[004/040] Train Acc: 0.683550 Loss: 0.992332 | Val Acc: 0.718929 loss: 0.866221\n",
            "saving model with acc 0.719\n",
            "[005/040] Train Acc: 0.694341 Loss: 0.954068 | Val Acc: 0.725483 loss: 0.841989\n",
            "saving model with acc 0.725\n",
            "[006/040] Train Acc: 0.702421 Loss: 0.922774 | Val Acc: 0.729775 loss: 0.824977\n",
            "saving model with acc 0.730\n",
            "[007/040] Train Acc: 0.709188 Loss: 0.898268 | Val Acc: 0.730654 loss: 0.819815\n",
            "saving model with acc 0.731\n",
            "[008/040] Train Acc: 0.715126 Loss: 0.875739 | Val Acc: 0.737109 loss: 0.803667\n",
            "saving model with acc 0.737\n",
            "[009/040] Train Acc: 0.720745 Loss: 0.856165 | Val Acc: 0.737142 loss: 0.798700\n",
            "saving model with acc 0.737\n",
            "[010/040] Train Acc: 0.725725 Loss: 0.838162 | Val Acc: 0.741337 loss: 0.789467\n",
            "saving model with acc 0.741\n",
            "[011/040] Train Acc: 0.729837 Loss: 0.821248 | Val Acc: 0.743711 loss: 0.777608\n",
            "saving model with acc 0.744\n",
            "[012/040] Train Acc: 0.734713 Loss: 0.806863 | Val Acc: 0.744329 loss: 0.776418\n",
            "saving model with acc 0.744\n",
            "[013/040] Train Acc: 0.738331 Loss: 0.792981 | Val Acc: 0.747045 loss: 0.773538\n",
            "saving model with acc 0.747\n",
            "[014/040] Train Acc: 0.741938 Loss: 0.780928 | Val Acc: 0.747256 loss: 0.769968\n",
            "saving model with acc 0.747\n",
            "[015/040] Train Acc: 0.744561 Loss: 0.769042 | Val Acc: 0.748654 loss: 0.767246\n",
            "saving model with acc 0.749\n",
            "[016/040] Train Acc: 0.748459 Loss: 0.756765 | Val Acc: 0.749175 loss: 0.763473\n",
            "saving model with acc 0.749\n",
            "[017/040] Train Acc: 0.751484 Loss: 0.745959 | Val Acc: 0.751533 loss: 0.758194\n",
            "saving model with acc 0.752\n",
            "[018/040] Train Acc: 0.754377 Loss: 0.735649 | Val Acc: 0.751858 loss: 0.757315\n",
            "saving model with acc 0.752\n",
            "[019/040] Train Acc: 0.757754 Loss: 0.725301 | Val Acc: 0.752915 loss: 0.754796\n",
            "saving model with acc 0.753\n",
            "[020/040] Train Acc: 0.759881 Loss: 0.715255 | Val Acc: 0.753533 loss: 0.755782\n",
            "saving model with acc 0.754\n",
            "[021/040] Train Acc: 0.762370 Loss: 0.706411 | Val Acc: 0.753273 loss: 0.755220\n",
            "[022/040] Train Acc: 0.764660 Loss: 0.698742 | Val Acc: 0.752102 loss: 0.754616\n",
            "[023/040] Train Acc: 0.767090 Loss: 0.689688 | Val Acc: 0.754151 loss: 0.753924\n",
            "saving model with acc 0.754\n",
            "[024/040] Train Acc: 0.769576 Loss: 0.681528 | Val Acc: 0.754232 loss: 0.754104\n",
            "saving model with acc 0.754\n",
            "[025/040] Train Acc: 0.771884 Loss: 0.673655 | Val Acc: 0.753012 loss: 0.756783\n",
            "[026/040] Train Acc: 0.773985 Loss: 0.667976 | Val Acc: 0.754899 loss: 0.755259\n",
            "saving model with acc 0.755\n",
            "[027/040] Train Acc: 0.776051 Loss: 0.659987 | Val Acc: 0.757240 loss: 0.756383\n",
            "saving model with acc 0.757\n",
            "[028/040] Train Acc: 0.778089 Loss: 0.653161 | Val Acc: 0.756216 loss: 0.756611\n",
            "[029/040] Train Acc: 0.779720 Loss: 0.646666 | Val Acc: 0.755858 loss: 0.755719\n",
            "[030/040] Train Acc: 0.782413 Loss: 0.640080 | Val Acc: 0.755533 loss: 0.759393\n",
            "[031/040] Train Acc: 0.784169 Loss: 0.633623 | Val Acc: 0.755679 loss: 0.761959\n",
            "[032/040] Train Acc: 0.785358 Loss: 0.627959 | Val Acc: 0.757712 loss: 0.756130\n",
            "saving model with acc 0.758\n",
            "[033/040] Train Acc: 0.787593 Loss: 0.622386 | Val Acc: 0.754476 loss: 0.762800\n",
            "[034/040] Train Acc: 0.788697 Loss: 0.616840 | Val Acc: 0.756980 loss: 0.759983\n",
            "[035/040] Train Acc: 0.790212 Loss: 0.611636 | Val Acc: 0.753484 loss: 0.766429\n",
            "[036/040] Train Acc: 0.791768 Loss: 0.606554 | Val Acc: 0.756102 loss: 0.766842\n",
            "[037/040] Train Acc: 0.793417 Loss: 0.601411 | Val Acc: 0.757029 loss: 0.765597\n",
            "[038/040] Train Acc: 0.795034 Loss: 0.596050 | Val Acc: 0.755386 loss: 0.768551\n",
            "[039/040] Train Acc: 0.796650 Loss: 0.591614 | Val Acc: 0.754996 loss: 0.772752\n",
            "[040/040] Train Acc: 0.797895 Loss: 0.586463 | Val Acc: 0.755695 loss: 0.768345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Hi7jTn3PX-m"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfUECMFCn5VG"
      },
      "source": [
        "Create a testing dataset, and load model from the saved checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PKjtAScPWtr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "389c31e9-ad88-4798-ceef-622b90f0232a"
      },
      "source": [
        "# create testing dataset\n",
        "test_set = TIMITDataset(test, None)\n",
        "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# create model and load weights from checkpoint\n",
        "model = Classifier().to(device)\n",
        "model.load_state_dict(torch.load(model_path))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-86-729a27d5b80e>:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "940TtCCdoYd0"
      },
      "source": [
        "Make prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84HU5GGjPqR0"
      },
      "source": [
        "predict = []\n",
        "model.eval() # set the model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(test_loader):\n",
        "        inputs = data\n",
        "        inputs = inputs.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
        "\n",
        "        for y in test_pred.cpu().numpy():\n",
        "            predict.append(y)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWDf_C-omElb"
      },
      "source": [
        "Write prediction to a CSV file.\n",
        "\n",
        "After finish running this block, download the file `prediction.csv` from the files section on the left-hand side and submit it to Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuljYSPHcZir"
      },
      "source": [
        "with open('prediction.csv', 'w') as f:\n",
        "    f.write('Id,Class\\n')\n",
        "    for i, y in enumerate(predict):\n",
        "        f.write('{},{}\\n'.format(i, y))"
      ],
      "execution_count": 88,
      "outputs": []
    }
  ]
}